# Memcache
(Youtube: Memcache Basics - Feb 5, 2013)[https://www.youtube.com/watch?v=TGl81wr8lz8&ab_channel=GoogleDevelopers]
# What is memcache
Memcache is an **in-memory** **Key-Value Pairs** data store

Fast and easy

anything serializable can be stored

language independent: Java/Python


# What do we use memcache for?

* Caching
    - datastore query results
    - user auth token and session data
    - APIs call or other computation results

* Share data cross app instances

# Why do we need memcache
* improve app perf
    - reduce latency
* reduce app cost
    - using memcache is free
    - The cost it saves: datastore query, API calls, CPU time, you need to pay for those

# How to use? Memcache APIs
Look for public docs

Third party lib, like Objectify


## General memcache usage pattern
Read-frequently and write-rarely data is most suitable

Datastore is the persistence, DB.

Data read with datastore: check if Memcache value exists
* if exists return that value
* else fetch from datastore and write to Memcache, return value

Data write with datastore
1. invalidate existing value in Memcache
    - either invalidate for specific entry
    - or invalidate the entire memcache 
2. Write value to datastore
    - optionally, update memcache entry


## Operations
* put(key, value)
* get(key)
* delete(key)

### Batch ops
further improve Memcache performance by reducing the number of network calls needed.
* getAll()
* putAll()
* deleteAll()

There is a limit on the size of Batch ops

### Atomic Ops
helps managing memcache data consistency in multi-instances/concurrent env
* increment(key, delta), incrementAll(): increment numeric values
* getidentifiable(), putIfUntouched(): providing mechanisum to update a value consistently by **concurrent** requests

### Other features
* Async calls: non-blocking api code
* namespace: separate data. e.g.
    - support multi-tenancy


# Caveats and solutions

## Memcache is volatile
Entries can be evicted anytime by various reasons
- handle cache-miss gracefully
- impliment write-through logic by backing memcache with datastore


## Memcache is not transactional
Could face race condition
- use `getIdentifiable()` and `putIfUntouched()` for optimistic locking

## Memcache is a limited resource
* only cache what is useful and necessary
* optimization: create objects, and even compress
* application should funtion without memcache